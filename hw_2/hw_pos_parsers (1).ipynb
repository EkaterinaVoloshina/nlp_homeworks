{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "hw_pos_parsers.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNG9TNJkjoq"
      },
      "source": [
        "# Домашняя работа №2. Работа с POS-тэггерами\n",
        "\n",
        "_Екатерина Волошина_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmeD1s-4kx3D"
      },
      "source": [
        "Импорт нужных модулей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2euxaHN46Us"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Co-vPi0Tpzk"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "from pymystem3 import Mystem\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")\n",
        "\n",
        "morph_parse = MorphAnalyzer()\n",
        "m = Mystem()"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIvEk2J5Tpzz"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "wpt = WordPunctTokenizer()"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuqcR2Y6jWQJ",
        "outputId": "5bacd310-ca2a-4a2a-ede2-43f909416e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem\n"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-16 19:17:11--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.242, 5.45.205.245, 5.45.205.241, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.242|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cache-mskstoredata10.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
            "--2020-10-16 19:17:11--  http://cache-mskstoredata10.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving cache-mskstoredata10.cdn.yandex.net (cache-mskstoredata10.cdn.yandex.net)... 37.9.96.21, 2a02:6b8:0:3706::19\n",
            "Connecting to cache-mskstoredata10.cdn.yandex.net (cache-mskstoredata10.cdn.yandex.net)|37.9.96.21|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.3’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  8.89MB/s    in 1.8s    \n",
            "\n",
            "2020-10-16 19:17:13 (8.89 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.3’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q84O9QTdm4Qq"
      },
      "source": [
        "## Тексты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dARLjDWHnVSG"
      },
      "source": [
        "В тексте на русском сложными для pos-теггинга могут быть глагол \"печь\", так как pos-тэггер может спутать с существительным, так же может спутать глагол \"пила\" с существительным. Вероятно, возникнут проблемы с \"родными\" и \"близкими\", которые здесь употреблены как существительные, а pos-тэггер может определить как прилагательные. Возможно, будут сложными местоимения-прилагательные, которые в правильных ответах отмечаются как местоимения, а pos-тэггер может отметить как прилагательные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsfzAetTTpzr"
      },
      "source": [
        "russian_text = \"\"\"Мое любимое хобби – печь пироги. \n",
        "Я стараюсь правильно питаться, поэтому слежу, чтобы белки, жиры и углеводы были в пределах нормы в моих пирогах. \n",
        "Среди моих любимых рецептов – пирог с яблоками и ореховый пирог с добавлением шотландского виски. \n",
        "У меня есть пара советов для тех, кто хочет печь пироги. \n",
        "Пшеничная мука должна быть просеяна, а духовой шкаф должен быть разогрет заранее. \n",
        "Еще я люблю красиво подавать пироги своим родным и близким. \n",
        "Для этого я использую три красивые чашки и тарелки с росписью, которые мне подарила моя сестра. \n",
        "Я завариваю чай, заранее купленный на рынке, и приглашаю всех на чаепитие с пирогом. \n",
        "Это наша семейная традиция, моя сестра с детства пила чай с пирогом.\"\"\""
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKTtzrZDoA18"
      },
      "source": [
        "Правильные части речи:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrBzALiKzQ0a"
      },
      "source": [
        "right_list = ['PRON', 'ADJF', 'NOUN', 'VERB', 'NOUN', 'PRON', 'VERB', 'ADVB', \n",
        "              'VERB', 'ADVB', 'VERB', 'CONJ', 'NOUN', 'NOUN', 'CONJ', 'NOUN', \n",
        "              'VERB', 'PREP', 'NOUN', 'NOUN', 'PREP', 'PRON', 'NOUN', 'PREP', \n",
        "              'PRON', 'ADJF', 'NOUN', 'NOUN', 'PREP', 'NOUN', 'CONJ', 'ADJF', \n",
        "              'NOUN', 'PREP', 'NOUN', 'ADJF', 'NOUN', 'PREP', 'PRON', 'VERB', \n",
        "              'NOUN', 'NOUN', 'PREP', 'PRON', 'PRON', 'VERB', 'VERB', 'NOUN', \n",
        "              'ADJF', 'NOUN', 'ADJF', 'VERB', 'VERB', 'CONJ', 'ADJF', 'NOUN', \n",
        "              'ADJF', 'VERB', 'VERB', 'ADVB', 'PRCL', 'PRON', 'VERB', 'ADVB', \n",
        "              'VERB', 'NOUN', 'PRON', 'NOUN', 'CONJ', 'NOUN', 'PREP', 'PRON', \n",
        "              'PRON', 'VERB', 'NUM', 'ADJF', 'NOUN', 'CONJ', 'NOUN', 'PREP', \n",
        "              'NOUN', 'PRON', 'PRON', 'VERB', 'PRON', 'NOUN', 'PRON', 'VERB', \n",
        "              'NOUN', 'ADVB', 'VERB', 'PREP', 'NOUN', 'CONJ', 'VERB', 'PRON', \n",
        "              'PREP', 'NOUN', 'PREP', 'NOUN', 'PRON', 'PRON', 'ADJF', 'NOUN',\n",
        "              'PRON', 'NOUN', 'PREP', 'NOUN', 'VERB', 'NOUN', 'PREP', 'NOUN']"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhLqQeiqjch"
      },
      "source": [
        "В английском тексте предполагается, что будут сложными случаи конверсии: studies/study, reading, finding, research, а также многозначные слова (well)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E0KfnUWTpzw"
      },
      "source": [
        "english_text = \"\"\"Sara Black is the Oxford University student. \n",
        "She studies philology because she loves books more than everything else in the world.\n",
        "She spends all her free time reading books. \n",
        "When she was a child, she wrote a tale about a princess and a magic well. \n",
        "Her main area of research is myths of Ancient Greece and Rome Empire about finding a treasure. \n",
        "Her father told her these stories when they were in Greece many years ago.\n",
        "When she decided to study philology, she chose this topic for her first research. \n",
        "Now she is studying Ancient Greek and Latin to work with original texts in the future.\"\"\""
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbd0LBsmrQiN"
      },
      "source": [
        "Правильные ответы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEQTbrCgn0fS"
      },
      "source": [
        "right_e_list = ['NOUN', 'NOUN', 'VERB', 'DET', 'NOUN', 'NOUN', 'NOUN',\n",
        "                'PRON', 'VERB', 'NOUN', 'CONJ', 'PRON', 'VERB', 'NOUN', 'ADVB', \n",
        "                'CONJ', 'NOUN', 'ADVB', 'PREP', 'DET', 'NOUN', 'PRON', 'VERB', 'PRON', 'PRON',\n",
        "                'ADJF', 'NOUN', 'VERB', 'NOUN', 'CONJ', 'PRON', 'VERB', 'DET', 'NOUN', 'PRON',\n",
        "                'VERB', 'DET', 'NOUN', 'PREP', 'DET', 'NOUN', 'CONJ', 'DET',\n",
        "                'NOUN', 'NOUN', 'PRON', 'ADJF', 'NOUN', 'PREP', 'NOUN', 'VERB',\n",
        "                'NOUN', 'PREP', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'PREP', \n",
        "                'VERB', 'DET', 'NOUN', 'PRON', 'NOUN', 'VERB', 'PRON', 'DET',\n",
        "                'NOUN', 'CONJ', 'PRON', 'VERB', 'PREP', 'NOUN', 'ADJF', 'NOUN',\n",
        "                'ADVB', 'CONJ', 'PRON', 'VERB', 'CONJ', 'VERB', 'NOUN', 'PRON',\n",
        "                'VERB', 'DET', 'NOUN', 'PREP', 'PRON', 'NUM', 'NOUN', 'ADVB', \n",
        "                'PRON', 'VERB', 'VERB', 'ADJF', 'NOUN', 'CONJ', 'NOUN', 'CONJ',\n",
        "                'VERB', 'PREP', 'ADJF', 'NOUN', 'PREP', 'DET', 'NOUN']"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZBsIfiqvqfU"
      },
      "source": [
        "## Анализ текста на русском языке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT0sMOS8xGh3"
      },
      "source": [
        "Функция, чтобы привести теги к тем, что используются в правильных ответах:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xpk57-NlGeD"
      },
      "source": [
        "def to_right(l):\n",
        "  new_list = []\n",
        "  russian_dict = {'NPRO':'PRON', 'ADJS':'ADJF', 'INFN':'VERB','PRTS':'VERB', \n",
        "                  'PRTF':'VERB', 'A':'ADJF', 'ADV':'ADVB', 'ADVPRO':'PRON', \n",
        "                  'ANUM':'NUM', 'APRO':'PRON', 'COM':'NOUN', \n",
        "                  'PART':'PRCL', 'PR':'PREP', 'S':'NOUN', 'SPRO':'PRON', \n",
        "                  'V':'VERB', 'DET':'PRON', 'ADJ':'ADJF', 'ADV':'ADVB', \n",
        "                  'SCONJ':'CONJ', 'AUX':'VERB', 'CCONJ':'CONJ',\n",
        "                  'ADP':'PREP', 'PUNCT':''}\n",
        "  for i in l:\n",
        "    if i in russian_dict and russian_dict[i] !='':\n",
        "      new_list.append(russian_dict[i])\n",
        "    elif i not in russian_dict:\n",
        "      new_list.append(i)\n",
        "  return new_list"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMMhaS-BxK1I"
      },
      "source": [
        "### Анализ с помощью PyMorphy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXc0SinqxKyS"
      },
      "source": [
        "token_text = wpt.tokenize(russian_text)\n",
        "pymorphy_list = []\n",
        "for word in token_text: \n",
        "    analyze = morph_parse.parse(word)\n",
        "    pos = analyze[0].tag.POS\n",
        "    if pos != None:\n",
        "        pymorphy_list.append(pos)\n",
        "pymorphy_list = to_right(pymorphy_list)"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sH6QQlxOP7"
      },
      "source": [
        "Посчитаем долю верных ответов для PyMorphy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8geDwIq95Rcj",
        "outputId": "d60aed32-3a35-4138-99e3-1d990269537e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(right_list, pymorphy_list)"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8392857142857143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucteRisbxdcw"
      },
      "source": [
        "### Анализ с помощью MyStem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjYfWpv-6Ayn"
      },
      "source": [
        "text = m.analyze(russian_text)"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtIQALszOWb1"
      },
      "source": [
        "mystem_list = []\n",
        "for word in text:\n",
        "  if 'analysis' in word:\n",
        "    parse = word.get('analysis')[0]\n",
        "    pos = parse['gr']\n",
        "    pos = pos.split('=')[0]\n",
        "    pos = pos.split(',')[0]\n",
        "    mystem_list.append(pos)"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeINpAq7xXAc"
      },
      "source": [
        "Посчитаем долю верных ответов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEXj1y1rSr1N",
        "outputId": "e2784488-14cb-4198-a76a-d646b414a4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mystem = to_right(mystem_list)\n",
        "accuracy_score(right_list, mystem)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9553571428571429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_92xJsWYxf7q"
      },
      "source": [
        "### Анализ с помощью Natasha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMey3ul4WnTD"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "morph_vocab = MorphVocab()"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umFgLScF0DCm"
      },
      "source": [
        "doc = Doc(russian_text)\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "natasha_list = [i.pos for i in doc.tokens]"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhhIrRJxjxg"
      },
      "source": [
        "Посчитаем долю верных ответов для Natasha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C2NQWG56PSw",
        "outputId": "2ccb347a-84a3-4de6-e708-657e3363facb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "natasha = to_right(natasha_list)\n",
        "accuracy_score(right_list, natasha)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9642857142857143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0SHl1ou0CGk"
      },
      "source": [
        "Как мы видим, лучше всего разметил POS-тэггер __Natasha__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbhhgRYRv1Ly"
      },
      "source": [
        "## Анализ текста на английском языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYNXU5Tg0KGO"
      },
      "source": [
        "Функция, которая приводит ответы POS-тэггеров к тэгам из правильных ответов: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkZKTjHlmVKA"
      },
      "source": [
        "def eng_to_right(l):\n",
        "  eng_dict = {'ADJ':'ADJF', 'ADP':'PREP', 'ADV':'ADVB', 'AUX':'VERB', \n",
        "                'CCONJ':'CONJ', 'PROPN':'NOUN', 'SCONJ':'CONJ', 'CC':'CONJ', \n",
        "                'CD':'NUM', 'DT':'DET', 'EX':'PRON', 'IN':'PREP', 'JJ':'ADJF', \n",
        "                'JJR':'ADJF', 'JJS':'ADJF', 'MD':'VERB', 'NN':'NOUN', \n",
        "                'NNP':'NOUN', 'NNS':'NOUN', 'PDT':'PRON', 'PRP':'PRON', \n",
        "                'PRP$':'PRON', 'RB':'ADVB', 'RBR':'ADVB', 'RBS':'ADVB', \n",
        "                'RP':'PART', 'TO':'CONJ', 'VB':'VERB', 'VBD':'VERB', \n",
        "                'VBG':'VERB', 'VBN':'VERB', 'VBP':'VERB', 'VBZ':'VERB', \n",
        "                'WDT':'PRON', 'WP':'PRON', 'WRB':'PRON'}\n",
        "  new_list = []\n",
        "  for i in l:\n",
        "    if i in eng_dict:\n",
        "      new_list.append(eng_dict[i])\n",
        "    elif i != 'PUNCT' and i != 'SPACE' and i.isalpha():\n",
        "      new_list.append(i)\n",
        "  return new_list"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFZdIrX10Ura"
      },
      "source": [
        "### Анализ с помощью NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjKoLTsMBK-i",
        "outputId": "9ac5e1c6-4da0-4222-cb53-302c7df8b1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "418Zw5UiAbhb"
      },
      "source": [
        "text = wpt.tokenize(english_text)\n",
        "nltk_list = nltk.pos_tag(text)\n",
        "nltk_list = [i[1] for i in nltk_list]"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0nh5pPs0alC"
      },
      "source": [
        "Посчитаем долю верных ответов для NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_OHPypvZ_e",
        "outputId": "89278c90-0665-41e3-bfc2-93651ddc251c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nltk_l = eng_to_right(nltk_list)\n",
        "accuracy_score(right_e_list, nltk_l)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8867924528301887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RTxHhM00eY0"
      },
      "source": [
        "### Анализ с помощью Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-W79gHGBOB2",
        "outputId": "4da9bb26-9ca5-4ca7-962c-6e98a44dd2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = Sentence(english_text)\n",
        "tagger = SequenceTagger.load('pos')\n",
        "tagger.predict(sentence)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-16 19:17:17,337 loading file /root/.flair/models/en-pos-ontonotes-v0.5.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xkDPDSFCLNo"
      },
      "source": [
        "flair_str = sentence.to_tagged_string()"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39timFcP0jxt"
      },
      "source": [
        "Из строчки получим список:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yi3mud2w8AK"
      },
      "source": [
        "flair_l = re.findall(r'(?<=\\<)[A-Z]+\\$?(?=\\>)', flair_str)\n",
        "flair_list = eng_to_right(flair_l)"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCGTeJGx0neY"
      },
      "source": [
        "Посчитаем долю верных ответов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VXZOzC5yIEx",
        "outputId": "d420f23d-40a3-4652-8da2-b7bab2f53175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(right_e_list, flair_list)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9245283018867925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLW77OyL0p9h"
      },
      "source": [
        "### Анализ с помощью SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFHblPebCcoi"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(english_text)\n",
        "\n",
        "spacy_list = []\n",
        "for i, s in enumerate(doc.sents):\n",
        "    for t in s:\n",
        "        spacy_list.append(t.pos_)"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk6x1WRV0sYe"
      },
      "source": [
        "Посчитаем долю верных ответов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10yK8BrC2FU9",
        "outputId": "2b2c6adb-befc-48e9-9e39-14e20a050d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy_list = eng_to_right(spacy_list)\n",
        "accuracy_score(right_e_list, spacy_list)"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8679245283018868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kj4DV_50wEU"
      },
      "source": [
        "## Функция, создающая группа\n",
        "\n",
        "Возьмем три группы: \"не\" + прилагательное, прилагательное + существительное и наречие + глагол, так как эти группы больше всего скажут нам об _оценке_ пользователя, так как просто слово \"хороший\" нам даст неправильную оценку, если перед ним идет отрицание. Так же полезно знать, что именно характеризуют оценочные прилагательные и наречия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoR7Nql31eSX"
      },
      "source": [
        "Функция написана с помощью Natasha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jie3Ls-o2ob_"
      },
      "source": [
        "def finding_groups(text):\n",
        "  groups_list = []\n",
        "  pos_tags = []\n",
        "  doc = Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for i in doc.tokens:\n",
        "    i.lemmatize(morph_vocab)\n",
        "  pos_tags = [(i.lemma, i.pos) for i in doc.tokens]\n",
        "  n_gram_list = []\n",
        "  for i in range(len(pos_tags)):\n",
        "    lemma = pos_tags[i][0]\n",
        "    tag = pos_tags[i][1]\n",
        "    if (i + 1) != len(pos_tags):\n",
        "      next_tag = pos_tags[i+1][1]\n",
        "      next_lemma = pos_tags[i+1][0]\n",
        "      if lemma == 'не' and next_tag == 'ADJ':\n",
        "        n_gram_list.append(' '.join([lemma, next_lemma]))\n",
        "      elif tag == 'ADJ' and next_tag == 'NOUN':\n",
        "        n_gram_list.append(' '.join([lemma, next_lemma]))\n",
        "      elif tag == 'ADV' and next_tag == 'VERB':\n",
        "        n_gram_list.append(' '.join([lemma, next_lemma]))\n",
        "  return n_gram_list"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CudjqdLg1trD"
      },
      "source": [
        "Посмотрим, какие группы функция нашла для нашего текста на русском:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYU0M7p77ma",
        "outputId": "c2b0a5d2-8c41-40d3-8f0e-42c14f6fa0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "finding_groups(russian_text)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['любимый хобби',\n",
              " 'правильно питаться',\n",
              " 'поэтому следить',\n",
              " 'любимый рецепт',\n",
              " 'шотландский виски',\n",
              " 'пшеничный мука',\n",
              " 'духовой шкаф',\n",
              " 'красиво подавать',\n",
              " 'красивый чашка',\n",
              " 'заранее купить',\n",
              " 'семейный традиция']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    }
  ]
}